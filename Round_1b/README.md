# 📄 Round 1B - Connecting the Dots Through Docs

A minimal-footprint Docker container (≤ 1 GB) that extracts and ranks the most relevant sections from a folder of PDFs based on a given persona and job-to-be-done. Using advanced NLP techniques and efficient ONNX models, this tool ranks document sections based on personas and their specific needs.

## 🎯 Key Features

- **Smart Content Understanding**:
  - Persona-based relevance ranking
  - Task-specific section extraction
  - Context-aware subsection analysis
  - Multi-document correlation

- **Optimized Performance**:
  - Sub-60 second processing
  - <1GB Docker image
  - CPU-only inference
  - Efficient ONNX runtime

- **Rich Analysis Output**:
  - Ranked section importance
  - Page-level granularity
  - Cross-document insights
  - Refined text summaries

## 🧠 Technical Implementation

```python
def rank_sections(pdfs, persona, task):
    # 1. Extract structured content
    sections = extract_sections(pdfs)
    
    # 2. Generate semantic embeddings
    embeddings = encode_text(sections)
    
    # 3. Compute relevance scores
    scores = rank_by_relevance(embeddings, persona, task)
    
    # 4. Extract key subsections
    insights = analyze_subsections(sections, scores)
    
    return ranked_results
```

## 📁 Project Structure

```
Challenge_1b/
├── Dockerfile                 # Multi-stage Docker build file (≤ 1 GB)
├── README.md                  # This documentation file
├── app/
│   ├── main.py                # Main application entry point
│   ├── pdf_parser.py          # Extracts text sections using PyMuPDF
│   ├── ranker.py              # Ranks sections using an ONNX MiniLM model
│   └── requirements.txt       # Runtime dependencies only
├── Collection 1/
│   ├── PDFs/                  # Source PDFs (e.g., travel guides)
│   ├── challenge1b_input.json
│   └── challenge1b_output.json # Generated by the container
├── Collection 2/              # Additional data collection (e.g., Acrobat tutorials)
└── Collection 3/              # Additional data collection (e.g., recipe guides)
```

## 📥 Input / 📤 Output Schema

### Input (`input/challenge1b_input.json`)
```json
{
  "challenge_info": {
    "challenge_id": "round_1b_002",
    "test_case_name": "Travel Planning"
  },
  "documents": [
    {
      "filename": "guide1.pdf",
      "title": "Guide 1"
    }
  ],
  "persona": {
    "role": "Travel Planner"
  },
  "job_to_be_done": {
    "task": "Plan a 4-day trip to South of France for 10 college friends"
  }
}
```

### Output (`output/challenge1b_output.json`)
```json
{
  "metadata": {
    "input_documents": ["guide1.pdf"],
    "persona": "Travel Planner",
    "job_to_be_done": "Plan a 4-day trip to South of France for 10 college friends"
  },
  "extracted_sections": [
    {
      "document": "guide1.pdf",
      "section_title": "4-Day Itinerary",
      "importance_rank": 1,
      "page_number": 5
    }
  ],
  "subsection_analysis": [
    {
      "document": "guide1.pdf",
      "refined_text": "Day 1: Arrive Nice – Old Town stroll…",
      "page_number": 5
    }
  ]
}
```

## 🚀 Quick Start

### Using Docker (Recommended)

1. Build the image:
```bash
docker build -t persona-doc-intel:1b .
```

2. Run the container:
```bash
docker run --rm \
  -v "$(pwd)/Collection 1:/workspace/input:ro" \
  -v "$(pwd)/Collection 1:/workspace/output" \
  persona-doc-intel:1b
```

## 🔧 Tech Stack

| Component | Size | Purpose |
|-----------|------|---------|
| onnxruntime 1.17.1 | 45MB | CPU-only inference |
| tokenizers 0.19.1 | 4MB | Fast BPE tokenization |
| pymupdf 1.24.1 | 3MB | PDF parsing |
| spacy 3.7.2 + en_core_web_sm | 12MB | NLP processing |
| MiniLM-L6 (ONNX) | 90MB | Semantic embeddings |

## 🔍 How It Works

1. **Content Extraction**: Uses PyMuPDF for efficient text and structure parsing
2. **Semantic Analysis**: Employs MiniLM-L6 ONNX model for understanding
3. **Relevance Ranking**: Computes similarity between content and user intent
4. **Subsection Analysis**: Identifies key details within relevant sections
5. **Result Generation**: Creates structured JSON with ranked insights

## 💡 Design Decisions

- **Why ONNX?** Optimal performance without GPU requirement
- **Why MiniLM?** Excellent accuracy/size trade-off
- **Why PyMuPDF?** Fast, memory-efficient PDF processing

## 🛠️ Troubleshooting

| Issue | Solution |
|-------|----------|
| `ModuleNotFoundError: transformers` | Re-build Docker image (transformers used only in build) |
| `tokenizer.json not found` | Re-build Docker image (file copied during build) |
| Image size > 1GB | Check final stage only has runtime dependencies |

## Team - Mental ACROBATics

## Members
- Raghav Manchanda
- Arjun Chouksey
- Pranjal Bhardwaj

